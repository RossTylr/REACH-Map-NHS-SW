{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01e_graph_centrality_analysis â€” Analyzing Network Structure\n",
    "\n",
    "### What this step does\n",
    "This notebook loads the graph created in `01d` and performs a **centrality analysis**. It calculates several key centrality metrics (Degree, Betweenness, Closeness) to identify the most important or influential nodes in the network. The results are added as attributes to the nodes, visualised, and exported.\n",
    "\n",
    "### Why this is useful\n",
    "- Introduces fundamental techniques for quantifying node importance in a network.\n",
    "- Helps answer questions like: \"Which facilities are the most connected?\" or \"Which nodes are most critical for connecting different parts of the network?\"\n",
    "- Demonstrates how to augment a graph with derived analytics and visualise these new properties.\n",
    "\n",
    "### Inputs\n",
    "- `outputs/01d_graph_creation/graph.graphml` (from the previous notebook)\n",
    "\n",
    "### Outputs\n",
    "- `outputs/01e_centrality_analysis/graph_with_centrality.graphml`\n",
    "- `outputs/01e_centrality_analysis/centrality_scores.csv`\n",
    "- `outputs/01e_centrality_analysis/01e_centrality_visualisation.png`\n",
    "\n",
    "### Key operations\n",
    "- Load a graph from a GraphML file.\n",
    "- Define single-purpose functions to calculate and attach different centrality scores.\n",
    "- Use `networkx.degree_centrality`, `networkx.betweenness_centrality`, and `networkx.closeness_centrality`.\n",
    "- Store the calculated scores as new node attributes.\n",
    "- Create a visualisation where node size is proportional to its betweenness centrality.\n",
    "- Export the augmented graph and a summary CSV of the scores."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 0: Imports and Configuration ---\n",
    "# 203 # This cell sets up the environment by importing necessary libraries and\n",
    "# 203 # defining the configuration. It follows the established pattern of using\n",
    "# 203 # pathlib.Path for file handling and a dataclass for configuration to ensure\n",
    "# 203 # that all paths are managed cleanly and relative to the project structure.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# 203 # Display preferences for better DataFrame output.\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    \"\"\"Configuration object for file paths and parameters.\"\"\"\n",
    "    input_dir: Path\n",
    "    output_dir: Path\n",
    "    input_graph_file: Path\n",
    "    output_graph_file: Path\n",
    "    scores_file: Path\n",
    "    viz_file: Path\n",
    "\n",
    "\n",
    "def setup_config() -> Config:\n",
    "    \"\"\"Initialises configuration and creates directories.\"\"\"\n",
    "    root_dir = Path(\".\")\n",
    "    input_dir = root_dir / \"outputs\" / \"01d_graph_creation\"\n",
    "    output_dir = root_dir / \"outputs\" / \"01e_centrality_analysis\"\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return Config(\n",
    "        input_dir=input_dir,\n",
    "        output_dir=output_dir,\n",
    "        input_graph_file=input_dir / \"graph.graphml\",\n",
    "        output_graph_file=output_dir / \"graph_with_centrality.graphml\",\n",
    "        scores_file=output_dir / \"centrality_scores.csv\",\n",
    "        viz_file=output_dir / \"01e_centrality_visualisation.png\",\n",
    "    )\n",
    "\n",
    "cfg = setup_config()\n",
    "\n",
    "print(\"--- Configuration Initialised ---\")\n",
    "print(f\"Input graph: {cfg.input_graph_file}\")\n",
    "print(f\"Outputs will be saved to: {cfg.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load Graph ---\n",
    "# 203 # This cell loads the graph created in the previous notebook.\n",
    "# 203 # Reading from GraphML is efficient and preserves all node/edge attributes,\n",
    "# 203 # making it the ideal format for passing graph data between steps.\n",
    "\n",
    "def load_graph(file_path: Path) -> nx.Graph:\n",
    "    \"\"\"Loads a graph from a GraphML file.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Graph file not found at {file_path}.\\n\"\n",
    "            f\"Please run notebook '01d_graph_creation_and_attributes.ipynb' first.\"\n",
    "        )\n",
    "    G = nx.read_graphml(file_path)\n",
    "    print(f\"Graph loaded from {file_path}.\")\n",
    "    print(f\"- Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"- Edges: {G.number_of_edges()}\")\n",
    "    return G\n",
    "\n",
    "# 203 # Execute the graph loading function.\n",
    "G = load_graph(cfg.input_graph_file)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Calculate Centrality Measures ---\n",
    "# 203 # This cell defines functions to compute various centrality metrics.\n",
    "# 203 # Each metric gets its own function for clarity. The main orchestrator function,\n",
    "# 203 # `calculate_and_set_centralities`, calls each of these and attaches the results\n",
    "# 203 # directly to the graph nodes as attributes.\n",
    "\n",
    "def calculate_degree_centrality(G: nx.Graph):\n",
    "    \"\"\"Calculates degree centrality and sets it as a node attribute.\"\"\"\n",
    "    # 203 # Degree centrality measures the number of direct connections a node has.\n",
    "    centrality = nx.degree_centrality(G)\n",
    "    nx.set_node_attributes(G, centrality, 'degree_centrality')\n",
    "    print(\"Calculated and attached 'degree_centrality'.\")\n",
    "\n",
    "def calculate_betweenness_centrality(G: nx.Graph):\n",
    "    \"\"\"Calculates betweenness centrality and sets it as a node attribute.\"\"\"\n",
    "    # 203 # Betweenness centrality identifies nodes that act as bridges.\n",
    "    # 203 # We use 'weight' to consider travel time in the shortest path calculations.\n",
    "    centrality = nx.betweenness_centrality(G, weight='weight', normalized=True)\n",
    "    nx.set_node_attributes(G, centrality, 'betweenness_centrality')\n",
    "    print(\"Calculated and attached 'betweenness_centrality'.\")\n",
    "\n",
    "def calculate_closeness_centrality(G: nx.Graph):\n",
    "    \"\"\"Calculates closeness centrality and sets it as a node attribute.\"\"\"\n",
    "    # 203 # Closeness centrality finds nodes that are, on average, closest to all others.\n",
    "    centrality = nx.closeness_centrality(G, distance='weight')\n",
    "    nx.set_node_attributes(G, centrality, 'closeness_centrality')\n",
    "    print(\"Calculated and attached 'closeness_centrality'.\")\n",
    "\n",
    "def calculate_and_set_centralities(G: nx.Graph):\n",
    "    \"\"\"Orchestrates calculation and assignment of all centrality measures.\"\"\"\n",
    "    calculate_degree_centrality(G)\n",
    "    calculate_betweenness_centrality(G)\n",
    "    calculate_closeness_centrality(G)\n",
    "\n",
    "# 203 # Execute the main calculation function.\n",
    "calculate_and_set_centralities(G)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Analyze and Export Centrality Scores ---\n",
    "# 203 # This cell extracts the computed centrality scores from the graph attributes\n",
    "# 203 # into a pandas DataFrame. This allows for easy sorting, analysis, and\n",
    "# 203 # exporting to a standard CSV format for reporting or use in other tools.\n",
    "\n",
    "def get_centrality_df(G: nx.Graph) -> pd.DataFrame:\n",
    "    \"\"\"Extracts node attributes into a DataFrame for analysis.\"\"\"\n",
    "    # 203 # Convert the graph's node data into a DataFrame.\n",
    "    # 203 # The `from_dict` method is a convenient way to achieve this.\n",
    "    df = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\n",
    "    # 203 # Reorder columns for logical presentation.\n",
    "    cols = [\n",
    "        'name', 'kind', 'degree_centrality', \n",
    "        'betweenness_centrality', 'closeness_centrality'\n",
    "    ]\n",
    "    df = df[cols].sort_values(by='betweenness_centrality', ascending=False)\n",
    "    df.index.name = 'node_id'\n",
    "    return df\n",
    "\n",
    "# 203 # Get the DataFrame and display the top 10 most central nodes.\n",
    "centrality_df = get_centrality_df(G)\n",
    "print(\"--- Top 10 Nodes by Betweenness Centrality ---\")\n",
    "print(centrality_df.head(10))\n",
    "\n",
    "# 203 # Save the full DataFrame to a CSV file.\n",
    "centrality_df.to_csv(cfg.scores_file)\n",
    "print(f\"\\nCentrality scores saved to {cfg.scores_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Visualize Centrality ---\n",
    "# 203 # This cell creates a visualisation where node size is mapped to its\n",
    "# 203 # betweenness centrality. This provides an intuitive visual representation\n",
    "# 203 # of the network's most critical nodes, making the analysis easier to interpret.\n",
    "\n",
    "def visualize_centrality(G: nx.Graph, file_path: Path):\n",
    "    \"\"\"Creates a graph plot with node sizes based on betweenness centrality.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    kinds = nx.get_node_attributes(G, 'kind')\n",
    "    betweenness = nx.get_node_attributes(G, 'betweenness_centrality')\n",
    "\n",
    "    # 203 # Scale node sizes for better visual impact.\n",
    "    # 203 # Adding a minimum size ensures even low-centrality nodes are visible.\n",
    "    node_sizes = [200 + (v * 4000) for v in betweenness.values()]\n",
    "\n",
    "    color_map = {'Clinic': '#3498db', 'Hospital': '#e74c3c', 'Warehouse': '#2ecc71'}\n",
    "    node_colors = [color_map.get(kinds.get(node, ''), '#bdc3c7') for node in G.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.9, ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.3, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_color='black', ax=ax)\n",
    "\n",
    "    ax.set_title(\"Network Centrality (Node Size by Betweenness)\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(file_path, dpi=200)\n",
    "    plt.show()\n",
    "    print(f\"Centrality visualisation saved to {file_path}\")\n",
    "\n",
    "# 203 # Execute the visualisation.\n",
    "visualize_centrality(G, cfg.viz_file)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Export Augmented Graph ---\n",
    "# 203 # This cell saves the updated graph, which now includes the centrality\n",
    "# 203 # scores as node attributes, to a new GraphML file. This ensures that\n",
    "# 203 # our analytical results are persisted for the next notebook in the series.\n",
    "\n",
    "def export_augmented_graph(G: nx.Graph, file_path: Path):\n",
    "    \"\"\"Saves the graph with centrality attributes to a new GraphML file.\"\"\"\n",
    "    nx.write_graphml(G, file_path)\n",
    "    print(f\"Augmented graph with centrality scores saved to {file_path}\")\n",
    "\n",
    "# 203 # Execute the export.\n",
    "export_augmented_graph(G, cfg.output_graph_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
