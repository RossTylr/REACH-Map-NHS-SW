{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec793faf-cb0d-4341-a756-b3d043b9e72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fae365d-ca32-40cc-bb99-267d4635f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 — Setup & paths\n",
    "# - Reuse the same BASE as 02a.\n",
    "# - Keep dependencies light: pandas, numpy, scipy.sparse.\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional, Tuple, Dict\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "BASE = Path(\"/Users/rosstaylor/Downloads/Code Repositories/REACH Map (NHS SW)\") \\\n",
    "    / \"GitHub Repo\" / \"REACH-Map-NHS-SW\" / \"data\" / \"raw\" / \"test_data_ICB_level\"\n",
    "TABLES   = BASE / \"tables\"\n",
    "MATRICES = BASE / \"matrices\"\n",
    "\n",
    "def _ok(msg: str) -> None: print(f\"[OK] {msg}\")\n",
    "def _warn(msg: str) -> None: warnings.warn(msg, stacklevel=2)\n",
    "def _die(msg: str) -> None: raise RuntimeError(msg)\n",
    "\n",
    "RESPONSE_THRESHOLDS    = (7, 15, 18, 40)\n",
    "SCENE_TO_AE_THRESHOLDS = (30, 45, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9e7e71-20e2-4d37-8395-44b29a5def2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Labels: N(demand)=336, J(stations)=14, K(acute)=3\n"
     ]
    }
   ],
   "source": [
    "# Step 1 — Load labels & pop from 02a, plus travel\n",
    "# - baseline_min_times.npz contains ordered lsoa_codes, station_lsoas, acute_lsoas.\n",
    "# - population parquet gives weights for KPIs.\n",
    "# - travel is the long OD with minutes.\n",
    "\n",
    "BASELINE_NPZ = MATRICES / \"baseline_min_times.npz\"\n",
    "if not BASELINE_NPZ.exists(): _die(\"Run 02a first: baseline_min_times.npz not found.\")\n",
    "\n",
    "with np.load(BASELINE_NPZ, allow_pickle=True) as z:\n",
    "    lsoa_codes    = z[\"lsoa_codes\"].astype(str)\n",
    "    station_lsoas = z[\"station_lsoas\"].astype(str)\n",
    "    acute_lsoas   = z[\"acute_lsoas\"].astype(str)\n",
    "\n",
    "lsoa_index = pd.Index(lsoa_codes, name=\"lsoa_code\")\n",
    "N, J, K = len(lsoa_index), len(station_lsoas), len(acute_lsoas)\n",
    "_ok(f\"Labels: N(demand)={N}, J(stations)={J}, K(acute)={K}\")\n",
    "\n",
    "POP_PARQUET = TABLES / \"population_by_lsoa.parquet\"\n",
    "pop = (pd.read_parquet(POP_PARQUET)\n",
    "         .set_index(\"lsoa_code\")[\"population\"]\n",
    "         .astype(\"float32\")\n",
    "         .reindex(lsoa_index)\n",
    "         .fillna(0.0))\n",
    "\n",
    "TRAVEL_CSV = BASE / \"travel_matrix_lsoa_icb.csv\"\n",
    "if not TRAVEL_CSV.exists(): _die(f\"Missing {TRAVEL_CSV.name}\")\n",
    "travel = pd.read_csv(TRAVEL_CSV, dtype={\"origin_lsoa\":\"string\",\"dest_lsoa\":\"string\"})\n",
    "time_col = next((c for c in (\"time_car_min\",\"time_min\",\"minutes\",\"drive_min\",\"t_min\") if c in travel.columns), None)\n",
    "if time_col is None: _die(\"No time column found in travel CSV.\")\n",
    "if time_col != \"time_car_min\":\n",
    "    travel = travel.rename(columns={time_col:\"time_car_min\"})\n",
    "travel[\"time_car_min\"] = travel[\"time_car_min\"].astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3a455c-ed3d-4be0-8408-5a9c5fed55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved R_csr.npz, C_csr.npz, matrix_metadata.npz\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — Build sparse matrices R (N×J) and C (N×K)\n",
    "# - R[i,j] = minutes from station-LSOA j → demand LSOA i\n",
    "# - C[i,k] = minutes from demand LSOA i → acute-LSOA k\n",
    "# - We coalesce duplicates by min() before building CSR.\n",
    "\n",
    "# Indexers\n",
    "lsoa_to_i   = {c: i for i, c in enumerate(lsoa_index)}\n",
    "station_to_j= {c: j for j, c in enumerate(station_lsoas)}\n",
    "acute_to_k  = {c: k for k, c in enumerate(acute_lsoas)}\n",
    "\n",
    "# ------- R (station → LSOA) -------\n",
    "sdf = travel.loc[travel[\"origin_lsoa\"].isin(station_lsoas),\n",
    "                 [\"origin_lsoa\",\"dest_lsoa\",\"time_car_min\"]].copy()\n",
    "if sdf.empty: _die(\"No station→LSOA rows in travel (check station LSOAs vs travel origins).\")\n",
    "sdf = (sdf.groupby([\"dest_lsoa\",\"origin_lsoa\"], as_index=False)[\"time_car_min\"]\n",
    "          .min())\n",
    "sdf = sdf.loc[sdf[\"dest_lsoa\"].isin(lsoa_index), :]\n",
    "\n",
    "i_idx = sdf[\"dest_lsoa\"].map(lsoa_to_i).to_numpy()\n",
    "j_idx = sdf[\"origin_lsoa\"].map(station_to_j).to_numpy()\n",
    "dataR = sdf[\"time_car_min\"].to_numpy(dtype=\"float32\")\n",
    "R = sparse.csr_matrix((dataR, (i_idx, j_idx)), shape=(N, J), dtype=\"float32\")\n",
    "\n",
    "# ------- C (LSOA → acute) -------\n",
    "cdf = travel.loc[travel[\"dest_lsoa\"].isin(acute_lsoas),\n",
    "                 [\"origin_lsoa\",\"dest_lsoa\",\"time_car_min\"]].copy()\n",
    "if cdf.empty: _die(\"No LSOA→acute rows in travel (check acute LSOAs vs travel dests).\")\n",
    "cdf = (cdf.groupby([\"origin_lsoa\",\"dest_lsoa\"], as_index=False)[\"time_car_min\"]\n",
    "          .min())\n",
    "cdf = cdf.loc[cdf[\"origin_lsoa\"].isin(lsoa_index), :]\n",
    "\n",
    "i_idxC = cdf[\"origin_lsoa\"].map(lsoa_to_i).to_numpy()\n",
    "k_idx  = cdf[\"dest_lsoa\"].map(acute_to_k).to_numpy()\n",
    "dataC  = cdf[\"time_car_min\"].to_numpy(dtype=\"float32\")\n",
    "C = sparse.csr_matrix((dataC, (i_idxC, k_idx)), shape=(N, K), dtype=\"float32\")\n",
    "\n",
    "# Persist\n",
    "sparse.save_npz(MATRICES / \"R_csr.npz\", R)\n",
    "sparse.save_npz(MATRICES / \"C_csr.npz\", C)\n",
    "np.savez_compressed(\n",
    "    MATRICES / \"matrix_metadata.npz\",\n",
    "    lsoa_codes=lsoa_codes,\n",
    "    station_lsoas=station_lsoas,\n",
    "    acute_lsoas=acute_lsoas,\n",
    ")\n",
    "_ok(\"Saved R_csr.npz, C_csr.npz, matrix_metadata.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d276a6-e093-4318-a4f8-b7867dcc4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 — Vectorised helpers for scenarios\n",
    "# - min_response_time: min across chosen station columns\n",
    "# - min_convey_time:  min across chosen acute columns\n",
    "# - scenario_eval:    KPIs (counts + pop-weighted %) at thresholds\n",
    "\n",
    "def min_response_time(R, active_cols=None) -> np.ndarray:\n",
    "    cols = np.arange(R.shape[1]) if active_cols is None else np.asarray(active_cols)\n",
    "    if cols.size == 0:\n",
    "        return np.full(R.shape[0], np.inf, dtype=\"float32\")\n",
    "    S = R[:, cols].tocsr()\n",
    "    A = S.toarray().astype(\"float32\")\n",
    "    # Minutes are strictly > 0; zeros in sparse → missing arcs\n",
    "    A[A == 0] = np.inf\n",
    "    return A.min(axis=1).astype(\"float32\")\n",
    "\n",
    "def min_convey_time(C, active_cols=None) -> np.ndarray:\n",
    "    cols = np.arange(C.shape[1]) if active_cols is None else np.asarray(active_cols)\n",
    "    if cols.size == 0:\n",
    "        return np.full(C.shape[0], np.inf, dtype=\"float32\")\n",
    "    S = C[:, cols].tocsr()\n",
    "    A = S.toarray().astype(\"float32\")\n",
    "    A[A == 0] = np.inf\n",
    "    return A.min(axis=1).astype(\"float32\")\n",
    "\n",
    "def scenario_eval(\n",
    "    R: sparse.csr_matrix,\n",
    "    C: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    resp_thresholds: Tuple[int,...] = RESPONSE_THRESHOLDS,\n",
    "    conv_thresholds: Tuple[int,...] = SCENE_TO_AE_THRESHOLDS,\n",
    "    station_cols: Optional[np.ndarray] = None,\n",
    "    acute_cols: Optional[np.ndarray] = None,\n",
    ") -> Dict[str, dict]:\n",
    "    t_resp = min_response_time(R, station_cols)\n",
    "    t_conv = min_convey_time(C, acute_cols)\n",
    "    total_pop = float(pop.sum())\n",
    "    out = {\"resp\": {}, \"conv\": {}}\n",
    "    for t in resp_thresholds:\n",
    "        mask = (t_resp <= t)\n",
    "        out[\"resp\"][t] = {\n",
    "            \"lsoas_cov\": int(mask.sum()),\n",
    "            \"pop_cov\": int(pop.values[mask].sum()),\n",
    "            \"pop_pct\": round(100.0 * float(pop.values[mask].sum()) / total_pop, 2) if total_pop else 0.0,\n",
    "        }\n",
    "    for t in conv_thresholds:\n",
    "        mask = (t_conv <= t)\n",
    "        out[\"conv\"][t] = {\n",
    "            \"lsoas_cov\": int(mask.sum()),\n",
    "            \"pop_cov\": int(pop.values[mask].sum()),\n",
    "            \"pop_pct\": round(100.0 * float(pop.values[mask].sum()) / total_pop, 2) if total_pop else 0.0,\n",
    "        }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0f28ea-6824-47c0-9797-d4a36d3ee842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CHECK] 02a min-time Parquets not present; skipping direct array compare.\n"
     ]
    }
   ],
   "source": [
    "# Robust acceptance back-check: compare to 02a if files exist, else skip gracefully.\n",
    "\n",
    "resp_parq = TABLES / \"resp_times_min.parquet\"\n",
    "conv_parq = TABLES / \"conv_times_min.parquet\"\n",
    "\n",
    "t_resp_R = min_response_time(R)  # all stations\n",
    "t_conv_C = min_convey_time(C)    # all acutes\n",
    "\n",
    "if resp_parq.exists() and conv_parq.exists():\n",
    "    resp_02a = (pd.read_parquet(resp_parq)\n",
    "                .set_index(\"lsoa_code\")[\"t_resp_min\"]\n",
    "                .reindex(lsoa_index).astype(\"float32\").to_numpy())\n",
    "    conv_02a = (pd.read_parquet(conv_parq)\n",
    "                .set_index(\"lsoa_code\")[\"t_conv_min\"]\n",
    "                .reindex(lsoa_index).astype(\"float32\").to_numpy())\n",
    "    tol = 1e-4\n",
    "    print(\"[CHECK] Match 02a mins:\",\n",
    "          f\"resp={np.nanmax(np.abs(resp_02a - t_resp_R)) < tol}\",\n",
    "          f\"conv={np.nanmax(np.abs(conv_02a - t_conv_C)) < tol}\")\n",
    "else:\n",
    "    print(\"[CHECK] 02a min-time Parquets not present; skipping direct array compare.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665c4f13-2584-4f6e-868d-0dae6adae279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BASE RESP]  T7:106 (30.75%) | T15:213 (62.28%) | T18:253 (75.11%) | T40:334 (99.26%)\n",
      "[BASE CONV]  T30:171 (51.09%) | T45:231 (69.04%) | T60:265 (78.74%)\n"
     ]
    }
   ],
   "source": [
    "base_kpis = scenario_eval(R, C, pop)\n",
    "print(\"[BASE RESP] \", \" | \".join(\n",
    "    f\"T{t}:{d['lsoas_cov']} ({d['pop_pct']}%)\" for t, d in base_kpis[\"resp\"].items()\n",
    "))\n",
    "print(\"[BASE CONV] \", \" | \".join(\n",
    "    f\"T{t}:{d['lsoas_cov']} ({d['pop_pct']}%)\" for t, d in base_kpis[\"conv\"].items()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "242bf281-4036-45f4-b00f-c5b89e3743dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WHAT-IF RESP]  T7:98 (28.06%) | T15:203 (59.17%) | T18:243 (71.79%) | T40:334 (99.26%)\n"
     ]
    }
   ],
   "source": [
    "# Step 5 — Quick “what-if” toggles (example snippets)\n",
    "# - Deactivate one station (e.g., first col) and re-evaluate.\n",
    "# - You can also pass an explicit list/array of active station columns.\n",
    "\n",
    "all_station_cols = np.arange(J)\n",
    "all_acute_cols   = np.arange(K)\n",
    "\n",
    "# Example: drop first station\n",
    "active_cols = all_station_cols[1:]\n",
    "whatif = scenario_eval(R, C, pop, station_cols=active_cols, acute_cols=all_acute_cols)\n",
    "\n",
    "print(\"[WHAT-IF RESP] \", \" | \".join(f\"T{t}:{d['lsoas_cov']} ({d['pop_pct']}%)\"\n",
    "                                    for t, d in whatif[\"resp\"].items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b67b6-7525-4ee5-b107-7d27f5078c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775f301-f6f6-4303-9782-53809da9c270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820bab8d-fc7b-4fcb-aa49-a9e9b881df84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5a1a3-f420-494d-9fad-f801a2cb6a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c355b9e-2b2e-499a-bc14-95204f94f98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
