{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc8c040",
   "metadata": {},
   "source": [
    "# Ambulance Station to Hospital Travel Time Analysis\n",
    "\n",
    "This notebook builds a directed bipartite graph connecting ambulance stations to acute hospitals using LSOA-level travel times and fallback estimates. It generates analytics, visualisations, and export artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c8932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "01b_directed_bipartite_graph — GeoPandas (BNG) |\n",
      "Root=/Users/rosstaylor/Downloads/Code Repositories/REACH Map (NHS SW)/GitHub\n",
      "Repo/REACH-Map-NHS-SW | SHA=41b45a5 | Python 3.11.13 | Pandas 2.3.2 |\n",
      "GeoPandas 1.1.1\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 0 — Status banner & utilities\n",
    "# - Purpose: central helpers for paths, logging, and safe \"status banner\".\n",
    "# - High level, no secrets: show versions, commit SHA, and environment sanity.\n",
    "# - Back-checks: project root discovery; graceful fallback if not git repo.\n",
    "# - Design: no side effects on import; pure helpers called by later steps.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import textwrap\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "PROJECT_MARKERS = {\".git\", \"README.md\", \"pyproject.toml\", \"requirements.txt\"}\n",
    "\n",
    "\n",
    "def find_project_root(start: Optional[Path] = None) -> Path:\n",
    "    \"\"\"Walk up from start (or CWD) until a project marker is found.\"\"\"\n",
    "    here = Path.cwd() if start is None else start\n",
    "    for parent in [here, *here.parents]:\n",
    "        if any((parent / m).exists() for m in PROJECT_MARKERS):\n",
    "            return parent\n",
    "    return here  # fallback: current directory\n",
    "\n",
    "\n",
    "def get_git_sha(root: Path) -> str:\n",
    "    \"\"\"Return short git SHA if available; otherwise 'unknown'.\"\"\"\n",
    "    try:\n",
    "        return subprocess.check_output(\n",
    "            [\"git\", \"rev-parse\", \"--short\", \"HEAD\"], cwd=str(root)\n",
    "        ).decode(\"utf-8\").strip()\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def banner(msg: str) -> None:\n",
    "    \"\"\"Pretty-print a banner box for key milestones and statuses.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(textwrap.fill(msg, width=78))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "def now_stamp() -> str:\n",
    "    \"\"\"Timestamp string for unique output folders.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "\n",
    "# Show initial status banner\n",
    "ROOT = find_project_root()\n",
    "SHA = get_git_sha(ROOT)\n",
    "banner(\n",
    "    f\"01b_directed_bipartite_graph — GeoPandas (BNG) | Root={ROOT} | SHA={SHA} | \"\n",
    "    f\"Python {sys.version.split()[0]} | Pandas {pd.__version__} | GeoPandas {gpd.__version__}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d6dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Config OK — outputs → /Users/rosstaylor/Downloads/Code Repositories/REACH Map\n",
      "(NHS SW)/GitHub Repo/REACH-Map-NHS-\n",
      "SW/outputs/01b_directed_bipartite_graph/20251026-2010 max_minutes=120,\n",
      "v_kph=50.0, fudge=1.3, top_k=3\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1 — Configuration & file contracts (no absolute paths)\n",
    "# - Purpose: centralise constants, CRS, thresholds, and I/O locations.\n",
    "# - Back-checks: assert directories exist; guide users with clear actions.\n",
    "# - Design: small dataclass for config; easy reuse in later notebooks.\n",
    "# - No hard-coded user paths; everything relative to project ROOT.\n",
    "\n",
    "BNG_EPSG = 27700  # British National Grid\n",
    "WGS84_EPSG = 4326\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    # Inputs (produced by step 01 and test slice)\n",
    "    data_dir: Path\n",
    "    test_dir: Path\n",
    "    stations_csv: Path\n",
    "    hospitals_csv: Path\n",
    "    travel_matrix_csv: Path\n",
    "    lsoa_gpkg: Path\n",
    "    lsoa_layer: str\n",
    "\n",
    "    # Outputs\n",
    "    out_dir: Path\n",
    "    out_stamp_dir: Path\n",
    "\n",
    "    # Edge/time params\n",
    "    max_minutes: int\n",
    "    v_kph: float\n",
    "    fudge: float\n",
    "    top_k: int\n",
    "\n",
    "\n",
    "cfg = Config(\n",
    "    data_dir=ROOT / \"data\",\n",
    "    test_dir=ROOT / \"data\" / \"raw\" / \"test_data_ICB_level\",\n",
    "    stations_csv=ROOT / \"data\" / \"raw\" / \"test_data_ICB_level\" / \"ambulance_stations_icb.csv\",\n",
    "    hospitals_csv=ROOT / \"data\" / \"raw\" / \"test_data_ICB_level\" / \"acute_hospitals_icb.csv\",\n",
    "    travel_matrix_csv=ROOT / \"data\" / \"raw\" / \"test_data_ICB_level\" / \"travel_matrix_lsoa_icb.csv\",\n",
    "    lsoa_gpkg=ROOT / \"data\" / \"raw\" / \"test_data_ICB_level\" / \"demographics_age_continuous_icb.gpkg\",\n",
    "    lsoa_layer=\"LSOA_continuous_age_icb\",\n",
    "    out_dir=ROOT / \"outputs\" / \"01b_directed_bipartite_graph\",\n",
    "    out_stamp_dir=ROOT / \"outputs\" / \"01b_directed_bipartite_graph\" / now_stamp(),\n",
    "    max_minutes=120,\n",
    "    v_kph=50.0,\n",
    "    fudge=1.30,\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "# Ensure directories exist\n",
    "cfg.out_dir.mkdir(parents=True, exist_ok=True)\n",
    "cfg.out_stamp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# File presence checks with helpful messages\n",
    "missing = [\n",
    "    p for p in [\n",
    "        cfg.stations_csv, cfg.hospitals_csv, cfg.lsoa_gpkg\n",
    "    ] if not p.exists()\n",
    "]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required input files:\\n  - \" + \"\\n  - \".join(map(str, missing)) +\n",
    "        \"\\nPlease run `01_develop_test_data_cornwall_icb` and/or place test slice files.\"\n",
    "    )\n",
    "\n",
    "banner(\n",
    "    f\"Config OK — outputs → {cfg.out_stamp_dir}\\n\"\n",
    "    f\"max_minutes={cfg.max_minutes}, v_kph={cfg.v_kph}, fudge={cfg.fudge}, top_k={cfg.top_k}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6365e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loaded stations=14, hospitals=3\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Travel matrix loaded, rows=112,560\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — Load inputs (stations, hospitals, LSOA polygons, optional travel)\n",
    "# - Purpose: read CSV/GPKG files; keep only canonical columns; light cleaning.\n",
    "# - Back-checks: basic schema checks; explain remediation if columns missing.\n",
    "# - Lat/Lon not trusted yet: we will validate and reproject later.\n",
    "# - Travel matrix optional: proceed without if not present.\n",
    "\n",
    "REQ_STATION_COLS = {\"code\", \"name\", \"latitude\", \"longitude\"}\n",
    "REQ_HOSP_COLS = {\"code\", \"name\", \"latitude\", \"longitude\"}\n",
    "TRAVEL_COLS = {\"origin_lsoa\", \"dest_lsoa\", \"time_car_min\"}\n",
    "\n",
    "stations_raw = pd.read_csv(cfg.stations_csv, dtype=\"string\").fillna(\"\")\n",
    "hospitals_raw = pd.read_csv(cfg.hospitals_csv, dtype=\"string\").fillna(\"\")\n",
    "banner(f\"Loaded stations={len(stations_raw):,}, hospitals={len(hospitals_raw):,}\")\n",
    "\n",
    "\n",
    "def normalise_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Lowercase column names and harmonise common alternatives.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    repl = {\n",
    "        \"lat\": \"latitude\",\n",
    "        \"lon\": \"longitude\",\n",
    "        \"long\": \"longitude\",\n",
    "        \"id\": \"code\",\n",
    "    }\n",
    "    df.rename(columns={k: v for k, v in repl.items() if k in df.columns}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "stations_raw = normalise_cols(stations_raw)\n",
    "hospitals_raw = normalise_cols(hospitals_raw)\n",
    "\n",
    "if not REQ_STATION_COLS.issubset(stations_raw.columns):\n",
    "    raise ValueError(\n",
    "        f\"Stations CSV missing columns: {REQ_STATION_COLS - set(stations_raw.columns)}\"\n",
    "    )\n",
    "if not REQ_HOSP_COLS.issubset(hospitals_raw.columns):\n",
    "    raise ValueError(\n",
    "        f\"Hospitals CSV missing columns: {REQ_HOSP_COLS - set(hospitals_raw.columns)}\"\n",
    "    )\n",
    "\n",
    "# LSOA polygons (BNG expected)\n",
    "lsoa_g = gpd.read_file(cfg.lsoa_gpkg, layer=cfg.lsoa_layer)\n",
    "if lsoa_g.crs is None:\n",
    "    raise ValueError(\"LSOA layer has no CRS. Expected EPSG:27700 (BNG).\")\n",
    "if lsoa_g.crs.to_epsg() != BNG_EPSG:\n",
    "    lsoa_g = lsoa_g.to_crs(epsg=BNG_EPSG)\n",
    "\n",
    "# Optional travel matrix\n",
    "travel = None\n",
    "if cfg.travel_matrix_csv.exists():\n",
    "    travel = pd.read_csv(cfg.travel_matrix_csv, dtype=\"string\")\n",
    "    travel.columns = [c.strip().lower() for c in travel.columns]\n",
    "    if not TRAVEL_COLS.issubset(travel.columns):\n",
    "        travel = None\n",
    "        banner(\"Travel matrix present but columns mismatch; ignoring for now.\")\n",
    "    else:\n",
    "        # normalise codes and minutes\n",
    "        for col in (\"origin_lsoa\", \"dest_lsoa\"):\n",
    "            travel[col] = travel[col].str.strip().str.upper()\n",
    "        travel[\"time_car_min\"] = pd.to_numeric(travel[\"time_car_min\"], errors=\"coerce\")\n",
    "        travel = travel.dropna(subset=[\"time_car_min\"]).reset_index(drop=True)\n",
    "        banner(f\"Travel matrix loaded, rows={len(travel):,}\")\n",
    "else:\n",
    "    banner(\"No travel matrix found — will compute fallback times from BNG distance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea13c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Auto-swapped lat/lon for 14 rows based on bounds check.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Auto-swapped lat/lon for 3 rows based on bounds check.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Geoms OK — stations=14, hospitals=3, CRS=BNG EPSG:27700\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3 — Lat/Lon sanity, dedupe, and geometry build (WGS84 → BNG)\n",
    "# - Purpose: canonicalise coordinates; auto-swap obviously inverted lat/lon.\n",
    "# - Back-checks: Cornwall bounds check; drop duplicates; assert unique codes.\n",
    "# - Output: GeoDataFrames in both WGS84 and BNG with x_bng/y_bng columns.\n",
    "\n",
    "SW_LON_MIN, SW_LON_MAX = -6.5, -3.0\n",
    "SW_LAT_MIN, SW_LAT_MAX = 49.0, 52.0\n",
    "\n",
    "\n",
    "def fix_latlon(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Auto-swap lat/lon if values are out of plausible SW England bounds.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors=\"coerce\")\n",
    "    df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors=\"coerce\")\n",
    "\n",
    "    mask_bad = ~(\n",
    "        (df[\"longitude\"].between(SW_LON_MIN, SW_LON_MAX)) &\n",
    "        (df[\"latitude\"].between(SW_LAT_MIN, SW_LAT_MAX))\n",
    "    )\n",
    "    swap_ok = (\n",
    "        (df[\"latitude\"].between(SW_LON_MIN, SW_LON_MAX)) &\n",
    "        (df[\"longitude\"].between(SW_LAT_MIN, SW_LAT_MAX))\n",
    "    )\n",
    "    to_swap = mask_bad & swap_ok\n",
    "    if to_swap.any():\n",
    "        df.loc[to_swap, [\"latitude\", \"longitude\"]] = df.loc[\n",
    "            to_swap, [\"longitude\", \"latitude\"]\n",
    "        ].values\n",
    "        banner(f\"Auto-swapped lat/lon for {to_swap.sum()} rows based on bounds check.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_geoms(df: pd.DataFrame, code_name: str) -> Tuple[gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    \"\"\"Return (WGS84 gdf, BNG gdf) with consistent schema and unique codes.\"\"\"\n",
    "    base = fix_latlon(df)[[\"code\", \"name\", \"latitude\", \"longitude\"]].dropna()\n",
    "    base = base.drop_duplicates(subset=[\"code\"]).reset_index(drop=True)\n",
    "\n",
    "    if base[\"code\"].duplicated().any():\n",
    "        raise ValueError(f\"Duplicate {code_name} codes found after de-duplication.\")\n",
    "\n",
    "    g_wgs = gpd.GeoDataFrame(\n",
    "        base,\n",
    "        geometry=gpd.points_from_xy(base[\"longitude\"], base[\"latitude\"]),\n",
    "        crs=f\"EPSG:{WGS84_EPSG}\",\n",
    "    )\n",
    "    g_bng = g_wgs.to_crs(epsg=BNG_EPSG)\n",
    "    g_bng[\"x_bng\"] = g_bng.geometry.x\n",
    "    g_bng[\"y_bng\"] = g_bng.geometry.y\n",
    "    return g_wgs, g_bng\n",
    "\n",
    "\n",
    "stations_wgs, stations_bng = to_geoms(stations_raw, \"station\")\n",
    "hospitals_wgs, hospitals_bng = to_geoms(hospitals_raw, \"hospital\")\n",
    "\n",
    "banner(\n",
    "    f\"Geoms OK — stations={len(stations_bng):,}, hospitals={len(hospitals_bng):,}, \"\n",
    "    f\"CRS=BNG EPSG:{BNG_EPSG}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4291959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Nearest LSOA attached to stations and hospitals.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4 — Map points to nearest LSOA (for optional official travel use)\n",
    "# - Purpose: attach nearest LSOA code to each station/hospital (BNG nearest).\n",
    "# - Back-checks: ensure LSOA has code column; warn if not found.\n",
    "# - Use: enables LSOA→LSOA time lookups when travel table present.\n",
    "\n",
    "LSOA_CODE_COL = next(\n",
    "    (c for c in [\"lsoa_code\", \"LSOA11CD\", \"lsoa11cd\", \"code\"]\n",
    "     if c in lsoa_g.columns),\n",
    "    None,\n",
    ")\n",
    "if LSOA_CODE_COL is None:\n",
    "    raise KeyError(\"Cannot find an LSOA code column in the GPKG layer.\")\n",
    "\n",
    "lsoa_centroids = lsoa_g.copy()\n",
    "lsoa_centroids[\"geometry\"] = lsoa_centroids.geometry.representative_point()\n",
    "\n",
    "\n",
    "def attach_nearest_lsoa(points_bng: gpd.GeoDataFrame, label: str) -> gpd.GeoDataFrame:\n",
    "    joined = gpd.sjoin_nearest(\n",
    "        points_bng[[\"code\", \"name\", \"geometry\"]],\n",
    "        lsoa_centroids[[LSOA_CODE_COL, \"geometry\"]],\n",
    "        how=\"left\",\n",
    "        distance_col=\"nearest_m\",\n",
    "    ).rename(columns={LSOA_CODE_COL: \"lsoa_code\"})\n",
    "    if joined[\"lsoa_code\"].isna().any():\n",
    "        banner(f\"Warning: {label} rows lack a nearest LSOA; check geometries/CRS.\")\n",
    "    return points_bng.merge(joined[[\"code\", \"lsoa_code\", \"nearest_m\"]], on=\"code\")\n",
    "\n",
    "\n",
    "stations_bng = attach_nearest_lsoa(stations_bng, \"stations\")\n",
    "hospitals_bng = attach_nearest_lsoa(hospitals_bng, \"hospitals\")\n",
    "\n",
    "banner(\"Nearest LSOA attached to stations and hospitals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaee844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Pairs built: 42 edges | 100% official times | Max minutes=120\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 — Build station×hospital pairs and compute travel minutes\n",
    "# - Purpose: construct bipartite candidate edges with time attributes.\n",
    "# - Back-checks: use official LSOA→LSOA times when available; else fallback.\n",
    "# - Fallback: BNG straight-line → minutes via v_kph × fudge; cap by max_minutes.\n",
    "\n",
    "def bng_dist_m(a_x: np.ndarray, a_y: np.ndarray, b_x: float, b_y: float) -> np.ndarray:\n",
    "    dx = a_x - b_x\n",
    "    dy = a_y - b_y\n",
    "    return np.sqrt(dx * dx + dy * dy)\n",
    "\n",
    "\n",
    "stations_b = stations_bng[[\"code\", \"name\", \"x_bng\", \"y_bng\", \"lsoa_code\"].copy()]\n",
    "stations_b = stations_b.rename(\n",
    "    columns={\"code\": \"station_code\", \"name\": \"station_name\", \"lsoa_code\": \"station_lsoa\"}\n",
    ")\n",
    "\n",
    "hospitals_b = hospitals_bng[[\"code\", \"name\", \"x_bng\", \"y_bng\", \"lsoa_code\"].copy()]\n",
    "hospitals_b = hospitals_b.rename(\n",
    "    columns={\"code\": \"hospital_code\", \"name\": \"hospital_name\", \"lsoa_code\": \"hospital_lsoa\"}\n",
    ")\n",
    "\n",
    "stations_b[\"key\"] = 1\n",
    "hospitals_b[\"key\"] = 1\n",
    "pairs = stations_b.merge(hospitals_b, on=\"key\").drop(columns=\"key\")\n",
    "\n",
    "# Optional official travel minutes via LSOA→LSOA\n",
    "if travel is not None:\n",
    "    tt = travel.copy()\n",
    "    tt = tt.rename(columns=str.lower)\n",
    "    tt = tt[[\"origin_lsoa\", \"dest_lsoa\", \"time_car_min\"]]\n",
    "    # Normalise code formatting for safer joins\n",
    "    for col in (\"origin_lsoa\", \"dest_lsoa\"):\n",
    "        tt[col] = tt[col].str.strip().str.upper()\n",
    "    for col in (\"station_lsoa\", \"hospital_lsoa\"):\n",
    "        pairs[col] = pairs[col].str.strip().str.upper()\n",
    "\n",
    "    pairs = pairs.merge(\n",
    "        tt,\n",
    "        left_on=[\"station_lsoa\", \"hospital_lsoa\"],\n",
    "        right_on=[\"origin_lsoa\", \"dest_lsoa\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    pairs[\"has_official_time\"] = pairs[\"time_car_min\"].notna()\n",
    "else:\n",
    "    pairs[\"time_car_min\"] = np.nan\n",
    "    pairs[\"has_official_time\"] = False\n",
    "\n",
    "# Fallback minutes from BNG straight-line distance\n",
    "fallback_mask = pairs[\"time_car_min\"].isna()\n",
    "if fallback_mask.any():\n",
    "    dist_m = bng_dist_m(\n",
    "        pairs.loc[fallback_mask, \"x_bng_x\"].to_numpy(),\n",
    "        pairs.loc[fallback_mask, \"y_bng_x\"].to_numpy(),\n",
    "        pairs.loc[fallback_mask, \"x_bng_y\"].to_numpy(),\n",
    "        pairs.loc[fallback_mask, \"y_bng_y\"].to_numpy(),\n",
    "    )\n",
    "    km = dist_m / 1000.0\n",
    "    fallback_min = (km / cfg.v_kph) * 60.0 * cfg.fudge\n",
    "    pairs.loc[fallback_mask, \"time_car_min\"] = fallback_min\n",
    "\n",
    "# Quality filter: keep pairs within max_minutes\n",
    "pairs = pairs[pairs[\"time_car_min\"] <= cfg.max_minutes].reset_index(drop=True)\n",
    "\n",
    "banner(\n",
    "    f\"Pairs built: {len(pairs):,} edges | \"\n",
    "    f\"{pairs['has_official_time'].mean():.0%} official times | \"\n",
    "    f\"Max minutes={cfg.max_minutes}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2776bd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Graph OK — nodes=17, edges=42 (stations=14, hospitals=3)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6 — Build directed bipartite graph (NetworkX attributes)\n",
    "# - Purpose: encode stations and hospitals as bipartite nodes; edges carry minutes.\n",
    "# - Back-checks: unique codes; consistent node attributes; simple sanity metrics.\n",
    "# - Output: in-memory graph, plus summary tables used for exports and mapping.\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add stations (bipartite=0) with name attribute\n",
    "station_nodes = [\n",
    "    (row.code, {\"bipartite\": 0, \"kind\": \"station\", \"name\": row.name})\n",
    "    for row in stations_bng.itertuples(index=False)\n",
    "]\n",
    "G.add_nodes_from(station_nodes)\n",
    "\n",
    "# Add hospitals (bipartite=1) with name attribute\n",
    "hospital_nodes = [\n",
    "    (row.code, {\"bipartite\": 1, \"kind\": \"hospital\", \"name\": row.name})\n",
    "    for row in hospitals_bng.itertuples(index=False)\n",
    "]\n",
    "G.add_nodes_from(hospital_nodes)\n",
    "\n",
    "# Add edges (station -> hospital)\n",
    "for r in pairs.itertuples(index=False):\n",
    "    G.add_edge(\n",
    "        r.station_code,\n",
    "        r.hospital_code,\n",
    "        time_min=float(r.time_car_min),\n",
    "        has_official=bool(r.has_official_time),\n",
    "        station_lsoa=r.station_lsoa,\n",
    "        hospital_lsoa=r.hospital_lsoa,\n",
    "    )\n",
    "\n",
    "if G.number_of_nodes() == 0 or G.number_of_edges() == 0:\n",
    "    raise RuntimeError(\"Empty graph — check inputs and pair filtering.\")\n",
    "\n",
    "banner(\n",
    "    f\"Graph OK — nodes={G.number_of_nodes():,}, edges={G.number_of_edges():,} \"\n",
    "    f\"(stations={stations_bng.shape[0]:,}, hospitals={hospitals_bng.shape[0]:,})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f4036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Top-K summary prepared (K=3).\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7 — Quick analytics (best hospital per station; top-K table)\n",
    "# - Purpose: convenient summaries for dashboards and mapping overlays.\n",
    "# - Back-checks: ensure each station has ≥1 reachable hospital.\n",
    "# - Outputs: two DataFrames for export: best and top-K by time_min.\n",
    "\n",
    "\n",
    "def best_by_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ix = df.groupby(\"station_code\")[\"time_car_min\"].idxmin()\n",
    "    return df.loc[ix, [\n",
    "        \"station_code\", \"station_name\", \"hospital_code\", \"hospital_name\",\n",
    "        \"time_car_min\", \"has_official_time\"\n",
    "    ]].sort_values(\"time_car_min\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def top_k_by_time(df: pd.DataFrame, k: int) -> pd.DataFrame:\n",
    "    return (\n",
    "        df.sort_values([\"station_code\", \"time_car_min\"])  # type: ignore[index]\n",
    "          .groupby(\"station_code\")\n",
    "          .head(k)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "pairs_view = pairs[[\n",
    "    \"station_code\", \"station_name\", \"hospital_code\", \"hospital_name\",\n",
    "    \"time_car_min\", \"has_official_time\"\n",
    "]].copy()\n",
    "\n",
    "best = best_by_time(pairs_view)\n",
    "topk = top_k_by_time(pairs_view, cfg.top_k)\n",
    "\n",
    "uncovered = set(stations_b[\"station_code\"]) - set(best[\"station_code\"])  # type: ignore[index]\n",
    "if uncovered:\n",
    "    banner(\n",
    "        f\"Warning: {len(uncovered)} station(s) lack reachable hospital within \"\n",
    "        f\"{cfg.max_minutes} min. Consider raising max_minutes.\"\n",
    "    )\n",
    "\n",
    "banner(f\"Top-K summary prepared (K={cfg.top_k}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a46ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Map saved to /Users/rosstaylor/Downloads/Code Repositories/REACH Map (NHS\n",
      "SW)/GitHub Repo/REACH-Map-NHS-\n",
      "SW/outputs/01b_directed_bipartite_graph/20251026-2010/01b_visual.png\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8 — GeoPandas map (BNG): LSOA boundary, stations, hospitals, optional lines\n",
    "# - Purpose: static, tile-free map in BNG suitable for reports/exports.\n",
    "# - Back-checks: CRS alignment; graceful skip if no pairs.\n",
    "# - Output: saved PNG/SVG; lightweight styling to remain readable.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "base = lsoa_g[[\"geometry\"]].to_crs(epsg=BNG_EPSG)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "base.plot(ax=ax, linewidth=0.2, edgecolor=\"0.8\", facecolor=\"none\")\n",
    "\n",
    "# Plot stations (circle) and hospitals (triangle) — default colours\n",
    "stations_bng.plot(ax=ax, markersize=20, alpha=0.9, label=\"Stations\")\n",
    "hospitals_bng.plot(ax=ax, markersize=30, alpha=0.9, label=\"Hospitals\", marker=\"^\")\n",
    "\n",
    "# Optional: draw best station→hospital lines for readability\n",
    "if not best.empty:\n",
    "    line_geoms: List[LineString] = []\n",
    "    for r in best.itertuples(index=False):\n",
    "        a = stations_bng.loc[stations_bng[\"code\"] == r.station_code, \"geometry\"].iloc[0]\n",
    "        b = hospitals_bng.loc[hospitals_bng[\"code\"] == r.hospital_code, \"geometry\"].iloc[0]\n",
    "        line_geoms.append(LineString([a, b]))\n",
    "    lines_g = gpd.GeoDataFrame(geometry=line_geoms, crs=f\"EPSG:{BNG_EPSG}\")\n",
    "    lines_g.plot(ax=ax, linewidth=0.4, alpha=0.5)\n",
    "\n",
    "ax.set_title(\"Stations → Hospitals (best by travel minutes)\\nBNG (EPSG:27700)\")\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Custom legend handles (GeoPandas doesn't auto-collect plot labels)\n",
    "station_handle = mlines.Line2D([], [], linestyle=\"None\", marker=\"o\", markersize=7, label=\"Stations\")\n",
    "hospital_handle = mlines.Line2D([], [], linestyle=\"None\", marker=\"^\", markersize=8, label=\"Hospitals\")\n",
    "edge_handle = mlines.Line2D([], [], linewidth=0.8, label=\"Best edges\")\n",
    "ax.legend(handles=[station_handle, hospital_handle, edge_handle], loc=\"lower right\")\n",
    "\n",
    "out_png = cfg.out_stamp_dir / \"01b_visual.png\"\n",
    "fig.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "banner(f\"Map saved to {out_png}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00829088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9 — Exports: nodes, edges, graphml, summaries, metadata receipt\n",
    "# - Purpose: persist clean artefacts for downstream 02a/02b/02c use.\n",
    "# - Back-checks: row counts > 0; write metadata receipt for reproducibility.\n",
    "# - Contract: stable column names; avoid surprises across notebooks.\n",
    "\n",
    "# Nodes (stations + hospitals)\n",
    "nodes_station = stations_bng[[\"code\", \"name\", \"x_bng\", \"y_bng\"]].copy()\n",
    "nodes_station[\"kind\"] = \"station\"\n",
    "nodes_hospital = hospitals_bng[[\"code\", \"name\", \"x_bng\", \"y_bng\"]].copy()\n",
    "nodes_hospital[\"kind\"] = \"hospital\"\n",
    "nodes = pd.concat([nodes_station, nodes_hospital], ignore_index=True)\n",
    "\n",
    "# Edges\n",
    "edges = pairs_view.rename(columns={\"time_car_min\": \"minutes\", \"has_official_time\": \"has_official\"})\n",
    "\n",
    "# Write CSVs\n",
    "nodes.to_csv(cfg.out_stamp_dir / \"nodes_station_hospital.csv\", index=False)\n",
    "edges.to_csv(cfg.out_stamp_dir / \"edges_station_to_hospital.csv\", index=False)\n",
    "best.to_csv(cfg.out_stamp_dir / \"station_best_hospital.csv\", index=False)\n",
    "topk.to_csv(cfg.out_stamp_dir / f\"station_top_{cfg.top_k}_hospitals.csv\", index=False)\n",
    "\n",
    "# GraphML\n",
    "nx.write_graphml(G, cfg.out_stamp_dir / \"station_hospital.graphml\")\n",
    "\n",
    "# Summary\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"nodes\", \"edges\", \"pct_official_times\", \"max_minutes\", \"top_k\"],\n",
    "    \"value\": [\n",
    "        G.number_of_nodes(),\n",
    "        G.number_of_edges(),\n",
    "        round(edges[\"has_official\"].mean() * 100, 1),\n",
    "        cfg.max_minutes,\n",
    "        cfg.top_k,\n",
    "    ],\n",
    "})\n",
    "summary.to_csv(cfg.out_stamp_dir / \"01b_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849dc41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Exports complete — CSVs, GraphML, summary, and metadata receipt written.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metadata receipt\n",
    "receipt = {\n",
    "    \"notebook\": \"01b_directed_bipartite_graph\",\n",
    "    \"git_sha\": SHA,\n",
    "    \"created_utc\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\n",
    "    \"crs\": {\"map_epsg\": BNG_EPSG, \"input_epsg\": WGS84_EPSG},\n",
    "    \"config\": {\n",
    "        \"max_minutes\": cfg.max_minutes,\n",
    "        \"v_kph\": cfg.v_kph,\n",
    "        \"fudge\": cfg.fudge,\n",
    "        \"top_k\": cfg.top_k,\n",
    "    },\n",
    "    \"inputs\": {\n",
    "        \"stations_csv\": str(cfg.stations_csv),\n",
    "        \"hospitals_csv\": str(cfg.hospitals_csv),\n",
    "        \"travel_matrix_csv\": str(cfg.travel_matrix_csv) if cfg.travel_matrix_csv.exists() else None,\n",
    "        \"lsoa_gpkg\": str(cfg.lsoa_gpkg),\n",
    "        \"lsoa_layer\": cfg.lsoa_layer,\n",
    "    },\n",
    "    \"outputs_dir\": str(cfg.out_stamp_dir),\n",
    "    \"counts\": {\n",
    "        \"stations\": int(stations_bng.shape[0]),\n",
    "        \"hospitals\": int(hospitals_bng.shape[0]),\n",
    "        \"edges\": int(edges.shape[0]),\n",
    "    },\n",
    "}\n",
    "with open(cfg.out_stamp_dir / \"01b_metadata.json\", \"w\") as f:\n",
    "    json.dump(receipt, f, indent=2)\n",
    "\n",
    "banner(\"Exports complete — CSVs, GraphML, summary, and metadata receipt written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1128fa-cf99-460d-82e4-05b8d20fb15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Ready for 02a/02b/02c. - 02a: population coverage vs thresholds. - 02b: sparse\n",
      "matrices (R and C) + caching. - 02c: MCLP/p-median with equity weights.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10 — Quality gates & friendly guidance\n",
    "# - Purpose: final assertions + hints to fix common issues quickly.\n",
    "# - Back-checks: minimum viable artefacts; uncover likely misconfigurations.\n",
    "# - Output: human-readable prompts for next steps (02a/02b/02c).\n",
    "\n",
    "assert nodes.shape[0] > 0, \"No nodes exported — check station/hospital inputs.\"\n",
    "assert edges.shape[0] > 0, (\n",
    "    \"No edges exported — try increasing max_minutes or review coordinates.\"\n",
    ")\n",
    "\n",
    "if edges[\"minutes\"].max() < 10:\n",
    "    banner(\"Heads-up: unusually small minutes; check units/CRS and fudge factor.\")\n",
    "\n",
    "if edges[\"has_official\"].mean() < 0.5 and cfg.travel_matrix_csv.exists():\n",
    "    banner(\n",
    "        \"Note: <50% official times used despite a travel matrix being present.\\n\"\n",
    "        \"Check LSOA code matching. Consider harmonising LSOA code formats.\"\n",
    "    )\n",
    "\n",
    "banner(\n",
    "    \"Ready for 02a/02b/02c.\\n\"\n",
    "    \"- 02a: population coverage vs thresholds.\\n\"\n",
    "    \"- 02b: sparse matrices (R and C) + caching.\\n\"\n",
    "    \"- 02c: MCLP/p-median with equity weights.\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
