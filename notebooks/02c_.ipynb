{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1719bc1-3857-4d0a-bb44-3cd82e61de9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5567ab-57ac-453a-86fd-ffe325d5c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Matrices loaded: R=(336, 14), C=(336, 3); N=336, J=14, K=3\n"
     ]
    }
   ],
   "source": [
    "# Step C0 — Setup & load matrices/labels/pop (idempotent)\n",
    "# - Reuses your test slice path and artefacts from 02a/02b.\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "import warnings, math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "BASE = Path(\"/Users/rosstaylor/Downloads/Code Repositories/REACH Map (NHS SW)\") \\\n",
    "    / \"GitHub Repo\" / \"REACH-Map-NHS-SW\" / \"data\" / \"raw\" / \"test_data_ICB_level\"\n",
    "TABLES   = BASE / \"tables\"\n",
    "MATRICES = BASE / \"matrices\"\n",
    "\n",
    "RESPONSE_THRESHOLDS    = (7, 15, 18, 40)\n",
    "SCENE_TO_AE_THRESHOLDS = (30, 45, 60)\n",
    "\n",
    "def _ok(msg: str) -> None: print(f\"[OK] {msg}\")\n",
    "def _warn(msg: str) -> None: warnings.warn(msg, stacklevel=2)\n",
    "def _die(msg: str) -> None: raise RuntimeError(msg)\n",
    "\n",
    "# Load matrices or reuse from memory if present\n",
    "try:\n",
    "    R\n",
    "    C\n",
    "except NameError:\n",
    "    from scipy import sparse\n",
    "    R = sparse.load_npz(MATRICES / \"R_csr.npz\")\n",
    "    C = sparse.load_npz(MATRICES / \"C_csr.npz\")\n",
    "\n",
    "meta = np.load(MATRICES / \"matrix_metadata.npz\", allow_pickle=True)\n",
    "lsoa_codes    = meta[\"lsoa_codes\"].astype(str)\n",
    "station_lsoas = meta[\"station_lsoas\"].astype(str)\n",
    "acute_lsoas   = meta[\"acute_lsoas\"].astype(str)\n",
    "lsoa_index = pd.Index(lsoa_codes, name=\"lsoa_code\")\n",
    "N, J, K = len(lsoa_index), len(station_lsoas), len(acute_lsoas)\n",
    "\n",
    "pop = (pd.read_parquet(TABLES / \"population_by_lsoa.parquet\")\n",
    "       .set_index(\"lsoa_code\")[\"population\"]\n",
    "       .astype(\"float32\").reindex(lsoa_index).fillna(0.0))\n",
    "\n",
    "_ok(f\"Matrices loaded: R={R.shape}, C={C.shape}; N={N}, J={J}, K={K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c94486a-6dd1-4b49-a539-63797fe2467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Baseline (from all stations/acutes) computed.\n"
     ]
    }
   ],
   "source": [
    "# Step C1 — Fast reducers & baseline (reuse if already defined)\n",
    "\n",
    "def min_response_time(R: sparse.csr_matrix, active_cols: Optional[np.ndarray]=None) -> np.ndarray:\n",
    "    cols = np.arange(R.shape[1]) if active_cols is None else np.asarray(active_cols)\n",
    "    if cols.size == 0:\n",
    "        return np.full(R.shape[0], np.inf, dtype=\"float32\")\n",
    "    S = R[:, cols].tocsr()\n",
    "    A = S.toarray().astype(\"float32\")\n",
    "    A[A == 0] = np.inf\n",
    "    return A.min(axis=1).astype(\"float32\")\n",
    "\n",
    "def scenario_eval(\n",
    "    R: sparse.csr_matrix,\n",
    "    C: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    resp_thresholds: Tuple[int,...] = RESPONSE_THRESHOLDS,\n",
    "    conv_thresholds: Tuple[int,...] = SCENE_TO_AE_THRESHOLDS,\n",
    "    station_cols: Optional[np.ndarray] = None,\n",
    "    acute_cols: Optional[np.ndarray] = None,\n",
    ") -> Dict[str, dict]:\n",
    "    t_resp = min_response_time(R, station_cols)\n",
    "    t_conv = min_response_time(C, acute_cols)  # same reducer works\n",
    "    total_pop = float(pop.sum())\n",
    "    out = {\"resp\": {}, \"conv\": {}, \"mean_resp_min\": float(np.average(np.nan_to_num(t_resp, nan=np.inf), weights=pop.values))}\n",
    "    for t in resp_thresholds:\n",
    "        mask = (t_resp <= t)\n",
    "        out[\"resp\"][t] = {\n",
    "            \"lsoas_cov\": int(mask.sum()),\n",
    "            \"pop_cov\": int(pop.values[mask].sum()),\n",
    "            \"pop_pct\": round(100.0 * float(pop.values[mask].sum()) / total_pop, 2) if total_pop else 0.0,\n",
    "        }\n",
    "    for t in conv_thresholds:\n",
    "        mask = (t_conv <= t)\n",
    "        out[\"conv\"][t] = {\n",
    "            \"lsoas_cov\": int(mask.sum()),\n",
    "            \"pop_cov\": int(pop.values[mask].sum()),\n",
    "            \"pop_pct\": round(100.0 * float(pop.values[mask].sum()) / total_pop, 2) if total_pop else 0.0,\n",
    "        }\n",
    "    return out\n",
    "\n",
    "baseline = scenario_eval(R, C, pop)\n",
    "_ok(\"Baseline (from all stations/acutes) computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defbe7df-44f1-47d7-962e-09a27df77b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step C2 — MCLP helpers (coverage sets) + greedy solver\n",
    "# - Build, for each demand i, the set of station columns that meet T minutes.\n",
    "# - Greedy: iteratively add station that covers the most uncovered weighted pop.\n",
    "\n",
    "def build_coverage_sets(R: sparse.csr_matrix, T: float) -> List[np.ndarray]:\n",
    "    M = R.copy().tocsr()\n",
    "    M.data = np.where(M.data <= T, 1.0, 0.0).astype(\"float32\")\n",
    "    M.eliminate_zeros()\n",
    "    # For each i (row), return array of j where time <= T\n",
    "    indptr, indices = M.indptr, M.indices\n",
    "    cov_sets = [indices[indptr[i]:indptr[i+1]].copy() for i in range(M.shape[0])]\n",
    "    return cov_sets\n",
    "\n",
    "def solve_mclp_greedy(\n",
    "    R: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    p: int,\n",
    "    T: float,\n",
    "    candidate_cols: Optional[np.ndarray] = None,\n",
    "    weights: Optional[pd.Series] = None,\n",
    ") -> dict:\n",
    "    J = R.shape[1]\n",
    "    cand = np.arange(J) if candidate_cols is None else np.asarray(candidate_cols)\n",
    "    cov_sets = build_coverage_sets(R, T)\n",
    "    w = pop.values.copy() if weights is None else (pop.values * weights.reindex(pop.index).fillna(1.0).values)\n",
    "    w = w.astype(\"float64\")\n",
    "\n",
    "    selected: List[int] = []\n",
    "    covered = np.zeros(R.shape[0], dtype=bool)\n",
    "    gains = []\n",
    "\n",
    "    for _ in range(min(p, cand.size)):\n",
    "        best_j, best_gain = None, -1.0\n",
    "        for j in cand:\n",
    "            if j in selected: continue\n",
    "            # Incremental gain: sum of weights for currently uncovered i that j can cover\n",
    "            gain = float(w[~covered][\n",
    "                [any(j in cs for cs in [cov_sets[i]]) for i in np.where(~covered)[0]]\n",
    "            ].sum()) if covered.any() else float(sum(w[i] for i in range(len(cov_sets)) if j in cov_sets[i]))\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_j = int(j)\n",
    "        if best_j is None: break\n",
    "        selected.append(best_j)\n",
    "        # Update covered set\n",
    "        js = set(selected)\n",
    "        for i, js_i in enumerate(cov_sets):\n",
    "            if not covered[i] and any(j in js for j in js_i):\n",
    "                covered[i] = True\n",
    "        gains.append(best_gain)\n",
    "\n",
    "    # KPIs after selection\n",
    "    sel = np.array(selected, dtype=int)\n",
    "    kpis = scenario_eval(R, C, pop, station_cols=sel, acute_cols=np.arange(C.shape[1]))\n",
    "    return {\n",
    "        \"selected_cols\": sel,\n",
    "        \"selected_lsoas\": station_lsoas[sel],\n",
    "        \"gains\": gains,\n",
    "        \"kpis\": kpis,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b62cec-7e5c-4e38-afcc-999dcc71bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step C3 — MCLP MILP (PuLP, optional). Falls back to greedy if PuLP missing.\n",
    "\n",
    "def solve_mclp_pulp(\n",
    "    R: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    p: int,\n",
    "    T: float,\n",
    "    candidate_cols: Optional[np.ndarray] = None,\n",
    "    weights: Optional[pd.Series] = None,\n",
    ") -> dict:\n",
    "    try:\n",
    "        import pulp\n",
    "    except Exception:\n",
    "        _warn(\"PuLP not available; using greedy MCLP instead.\")\n",
    "        return solve_mclp_greedy(R, pop, p, T, candidate_cols, weights)\n",
    "\n",
    "    cand = np.arange(R.shape[1]) if candidate_cols is None else np.asarray(candidate_cols)\n",
    "    cov_sets = build_coverage_sets(R, T)\n",
    "    w = pop.values.copy() if weights is None else (pop.values * weights.reindex(pop.index).fillna(1.0).values)\n",
    "    w = w.astype(\"float64\")\n",
    "\n",
    "    prob = pulp.LpProblem(\"MCLP\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"x\", list(cand), lowBound=0, upBound=1, cat=pulp.LpBinary)\n",
    "    y = pulp.LpVariable.dicts(\"y\", list(range(R.shape[0])), lowBound=0, upBound=1, cat=pulp.LpContinuous)\n",
    "\n",
    "    # Coverage constraints: y_i ≤ Σ_j∈cover(i) x_j\n",
    "    for i, js in enumerate(cov_sets):\n",
    "        in_cand = [int(j) for j in js if j in set(cand)]\n",
    "        if in_cand:\n",
    "            prob += (y[i] <= pulp.lpSum(x[j] for j in in_cand))\n",
    "        else:\n",
    "            prob += (y[i] <= 0)\n",
    "\n",
    "    # Cardinality: Σ x_j = p\n",
    "    prob += pulp.lpSum(x[j] for j in cand) == p\n",
    "\n",
    "    # Objective\n",
    "    prob += pulp.lpSum(w[i] * y[i] for i in range(R.shape[0]))\n",
    "\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    selected = np.array([j for j in cand if pulp.value(x[j]) > 0.5], dtype=int)\n",
    "\n",
    "    kpis = scenario_eval(R, C, pop, station_cols=selected, acute_cols=np.arange(C.shape[1]))\n",
    "    return {\n",
    "        \"selected_cols\": selected,\n",
    "        \"selected_lsoas\": station_lsoas[selected],\n",
    "        \"solver\": \"PuLP/CBC\",\n",
    "        \"kpis\": kpis,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e463acb0-4fdd-471d-bb6a-308ebece771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step C4 — p-median (PuLP with k-nearest), greedy fallback\n",
    "# - Build k-nearest arcs per demand to keep model small (k ~ 10–12 good here).\n",
    "\n",
    "def _knn_arcs(R: sparse.csr_matrix, k: int = 12) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    # Returns per i: (j_idx, t_ij) sorted by time, truncated at k and finite\n",
    "    out = []\n",
    "    A = R.tocsr()\n",
    "    for i in range(A.shape[0]):\n",
    "        row = A.getrow(i)\n",
    "        js, ts = row.indices, row.data\n",
    "        if js.size == 0:\n",
    "            out.append((np.array([], dtype=int), np.array([], dtype=\"float32\")))\n",
    "            continue\n",
    "        order = np.argsort(ts)\n",
    "        js_sorted = js[order][:k]\n",
    "        ts_sorted = ts[order][:k].astype(\"float32\")\n",
    "        out.append((js_sorted, ts_sorted))\n",
    "    return out\n",
    "\n",
    "def solve_pmedian_pulp(\n",
    "    R: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    p: int,\n",
    "    k_nearest: int = 12,\n",
    "    weights: Optional[pd.Series] = None,\n",
    ") -> dict:\n",
    "    try:\n",
    "        import pulp\n",
    "    except Exception:\n",
    "        _warn(\"PuLP not available; using greedy p-median instead.\")\n",
    "        return solve_pmedian_greedy(R, pop, p, k_nearest, weights)\n",
    "\n",
    "    knn = _knn_arcs(R, k=k_nearest)\n",
    "    w = pop.values.copy() if weights is None else (pop.values * weights.reindex(pop.index).fillna(1.0).values)\n",
    "    w = w.astype(\"float64\")\n",
    "\n",
    "    prob = pulp.LpProblem(\"p_median\", pulp.LpMinimize)\n",
    "    x = pulp.LpVariable.dicts(\"x\", list(range(R.shape[1])), lowBound=0, upBound=1, cat=pulp.LpBinary)\n",
    "    z = {}  # assignment vars only on knn arcs\n",
    "\n",
    "    # Create z_ij only where knn arc exists\n",
    "    for i, (js, ts) in enumerate(knn):\n",
    "        for j in js:\n",
    "            z[(i, int(j))] = pulp.LpVariable(f\"z_{i}_{int(j)}\", lowBound=0, upBound=1, cat=pulp.LpContinuous)\n",
    "\n",
    "    # Each demand assigned to exactly one open facility among its knn\n",
    "    for i, (js, _) in enumerate(knn):\n",
    "        if js.size > 0:\n",
    "            prob += pulp.lpSum(z[(i, int(j))] for j in js) == 1\n",
    "        else:\n",
    "            # No arcs: skip (or could add big-M to a dummy facility)\n",
    "            pass\n",
    "\n",
    "    # Cannot assign to closed facilities\n",
    "    for (i, j), var in z.items():\n",
    "        prob += var <= x[j]\n",
    "\n",
    "    # Exactly p facilities\n",
    "    prob += pulp.lpSum(x[j] for j in range(R.shape[1])) == p\n",
    "\n",
    "    # Objective: Σ_i Σ_j w_i * t_ij * z_ij\n",
    "    obj_terms = []\n",
    "    for i, (js, ts) in enumerate(knn):\n",
    "        for j, t in zip(js, ts):\n",
    "            obj_terms.append(w[i] * float(t) * z[(i, int(j))])\n",
    "    prob += pulp.lpSum(obj_terms)\n",
    "\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "    selected = np.array([j for j in range(R.shape[1]) if pulp.value(x[j]) > 0.5], dtype=int)\n",
    "\n",
    "    # KPIs\n",
    "    t_resp_sel = min_response_time(R, selected)\n",
    "    mean_time = float(np.average(t_resp_sel, weights=pop.values))\n",
    "    kpis = scenario_eval(R, C, pop, station_cols=selected, acute_cols=np.arange(C.shape[1]))\n",
    "    kpis[\"mean_resp_min\"] = mean_time\n",
    "\n",
    "    return {\n",
    "        \"selected_cols\": selected,\n",
    "        \"selected_lsoas\": station_lsoas[selected],\n",
    "        \"solver\": \"PuLP/CBC (k-nearest)\",\n",
    "        \"kpis\": kpis,\n",
    "    }\n",
    "\n",
    "def solve_pmedian_greedy(\n",
    "    R: sparse.csr_matrix,\n",
    "    pop: pd.Series,\n",
    "    p: int,\n",
    "    k_nearest: int = 12,\n",
    "    weights: Optional[pd.Series] = None,\n",
    ") -> dict:\n",
    "    # Simple forward-selection: add the station that most reduces weighted mean time\n",
    "    w = pop.values.copy() if weights is None else (pop.values * weights.reindex(pop.index).fillna(1.0).values)\n",
    "    w = w.astype(\"float64\")\n",
    "    selected: List[int] = []\n",
    "    current = np.full(R.shape[0], np.inf, dtype=\"float32\")\n",
    "\n",
    "    for _ in range(min(p, R.shape[1])):\n",
    "        best_j, best_obj = None, math.inf\n",
    "        for j in range(R.shape[1]):\n",
    "            if j in selected: continue\n",
    "            trial = np.minimum(current, R[:, j].toarray().ravel().astype(\"float32\"))\n",
    "            trial_wavg = float(np.average(np.nan_to_num(trial, nan=np.inf), weights=w))\n",
    "            if trial_wavg < best_obj:\n",
    "                best_obj, best_j = trial_wavg, j\n",
    "        if best_j is None: break\n",
    "        selected.append(best_j)\n",
    "        current = np.minimum(current, R[:, best_j].toarray().ravel().astype(\"float32\"))\n",
    "\n",
    "    kpis = scenario_eval(R, C, pop, station_cols=np.array(selected), acute_cols=np.arange(C.shape[1]))\n",
    "    kpis[\"mean_resp_min\"] = float(np.average(np.nan_to_num(current, nan=np.inf), weights=w))\n",
    "    return {\n",
    "        \"selected_cols\": np.array(selected, dtype=int),\n",
    "        \"selected_lsoas\": station_lsoas[np.array(selected, dtype=int)],\n",
    "        \"solver\": \"greedy\",\n",
    "        \"kpis\": kpis,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb9dd1f-3523-4ac1-9870-64be1c06678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BASE] | T7:106 (30.75%) | T15:213 (62.28%) | T18:253 (75.11%) | T40:334 (99.26%) | mean_resp=13.04 min\n",
      "[MCLP] | T7:97 (28.39%) | T15:193 (56.56%) | T18:233 (69.39%) | T40:334 (99.26%) | mean_resp=14.17 min\n",
      "[PMED] | T7:97 (28.39%) | T15:193 (56.56%) | T18:233 (69.39%) | T40:334 (99.26%) | mean_resp=14.17 min\n",
      "[OK] Wrote mclp_solution_p10_T15.csv and pmedian_solution_p10.csv\n"
     ]
    }
   ],
   "source": [
    "# Step C5 — Run example experiments + save CSVs\n",
    "# - Tune p and T as needed (e.g., p=10, T=15).\n",
    "# - Outputs: CSVs with chosen station LSOAs and KPI deltas.\n",
    "\n",
    "p = min(10, J)     # example: pick up to 10 stations\n",
    "T = 15             # MCLP threshold (minutes)\n",
    "\n",
    "# MCLP\n",
    "mclp = solve_mclp_pulp(R, pop, p=p, T=T)  # falls back to greedy if PuLP not available\n",
    "sel_mclp = mclp[\"selected_cols\"]\n",
    "kpis_mclp = mclp[\"kpis\"]\n",
    "\n",
    "# p-median\n",
    "pmed = solve_pmedian_pulp(R, pop, p=p, k_nearest=12)  # falls back to greedy\n",
    "sel_pmed = pmed[\"selected_cols\"]\n",
    "kpis_pmed = pmed[\"kpis\"]\n",
    "\n",
    "# Baseline KPIs for delta\n",
    "base = scenario_eval(R, C, pop)\n",
    "\n",
    "def _kpi_line(title, kpis):\n",
    "    return f\"{title} | \" + \" | \".join(f\"T{t}:{d['lsoas_cov']} ({d['pop_pct']}%)\"\n",
    "                                      for t, d in kpis[\"resp\"].items()) \\\n",
    "           + f\" | mean_resp={kpis.get('mean_resp_min', float('nan')):.2f} min\"\n",
    "\n",
    "print(_kpi_line(\"[BASE]\", base))\n",
    "print(_kpi_line(\"[MCLP]\", kpis_mclp))\n",
    "print(_kpi_line(\"[PMED]\", kpis_pmed))\n",
    "\n",
    "# Save selections\n",
    "mclp_df = pd.DataFrame({\n",
    "    \"station_col\": sel_mclp,\n",
    "    \"station_lsoa\": station_lsoas[sel_mclp],\n",
    "})\n",
    "pmed_df = pd.DataFrame({\n",
    "    \"station_col\": sel_pmed,\n",
    "    \"station_lsoa\": station_lsoas[sel_pmed],\n",
    "})\n",
    "\n",
    "mclp_df.to_csv(MATRICES / f\"mclp_solution_p{p}_T{T}.csv\", index=False)\n",
    "pmed_df.to_csv(MATRICES / f\"pmedian_solution_p{p}.csv\", index=False)\n",
    "_ok(f\"Wrote mclp_solution_p{p}_T{T}.csv and pmedian_solution_p{p}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3147e5eb-e2cf-488a-a02c-ef3646cac272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Equity weights set: IMD Q1 boosted to 1.5x.\n",
      "[MCLP + Equity] | T7:97 (28.39%) | T15:193 (56.56%) | T18:233 (69.39%) | T40:334 (99.26%) | mean_resp=14.17 min\n"
     ]
    }
   ],
   "source": [
    "# Step C6 — Equity weights hook (optional)\n",
    "# - Example: IMD Q1 = 1.5; others = 1.0\n",
    "\n",
    "try:\n",
    "    equity = pd.read_parquet(TABLES / \"lsoa_lookup_equity.parquet\").set_index(\"lsoa_code\")\n",
    "    w = pd.Series(1.0, index=lsoa_index, dtype=\"float32\")\n",
    "    if \"imd_quintile\" in equity.columns:\n",
    "        w.loc[equity[\"imd_quintile\"] == 1] = 1.5\n",
    "        _ok(\"Equity weights set: IMD Q1 boosted to 1.5x.\")\n",
    "        # Re-run a weighted MCLP\n",
    "        mclp_w = solve_mclp_pulp(R, pop, p=p, T=T, weights=w)\n",
    "        print(_kpi_line(\"[MCLP + Equity]\", mclp_w[\"kpis\"]))\n",
    "except Exception as e:\n",
    "    _warn(f\"Equity weighting skipped: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830cc9b-ea36-4784-9c6e-4470f5a1be26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ee190-9180-4802-a85a-2c338d8d7d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6c053-a88d-45ad-9387-e100232d1225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5e1a2-c459-40be-b6ba-d92e77df0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
